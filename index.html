<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="google-site-verification" content="CPH3dW_U0N82lUK7MiqGgbH2WCSdaLjgcaXefMjhysI" />
  <title>Jalend Bantupalli</title>
  <meta name="author" content="Jalend Bantupalli">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <header class="navbar">
    <nav class="container">
      <a href="/" class="nav-link">Home</a>
      <a href="/blog/index.html" class="nav-link">Blog</a>
    </nav>
  </header>

  <main class="container">
    <section class="intro">
      <div class="intro-content">
        <h1 class="name">Jalend Bantupalli</h1>
        <p class="title">
          Research Scientist ‚Äì LLMs, Program Synthesis, Embodied Agents
          <br>
          jbantupalli [at] ucsd [dot] edu
        </p>
        <p>
          I'm a Member of Technical Staff at <a href="https://www.myolab.ai">MyoLab</a>, working on LLM-based
          reasoning systems. I completed my Master‚Äôs in Computer Science at
          <a href="https://ucsd.edu/">UC San Diego</a>, where I focused on
          LLM Reasoning and Program Synthesis. Previously, I worked at
          Google and Microsoft on applied AI systems.
        </p>
        <p>
          At Google, I worked on <a href="https://research.google/teams/network-infrastructure/">Gemini
            Networking</a>, and at Microsoft, I contributed to <a
            href="https://www.microsoft.com/en-us/dynamics-365/solutions/sales-and-marketing">AI-powered
            Dynamics 365</a>. I earned my B.Tech from IIT Kharagpur, where I
          was advised by Professor Animesh Mukherjee on fairness in NLP,
          culminating in our paper on decoding demographic bias.
        </p>
        <div class="social-links">
          <a href="mailto:jalend.bantupalli@gmail.com">Email</a> /
          <a href="data/Resume.pdf">CV</a> /
          <a href="https://www.linkedin.com/in/jalend-bantupalli-3759a4196/">LinkedIn</a> /
          <a href="https://scholar.google.com/citations?user=B-cMjmgAAAAJ&hl=en">Scholar</a> /
          <a href="https://x.com/JalendBantupal2">Twitter</a> /
          <a href="https://github.com/Jalend15/">Github</a>
        </div>
      </div>
      <div class="profile-sidebar">
        <img src="images/tmp1.png" class="profile-photo" alt="profile photo">
        <div class="logos">
          <img src="images/ucsd.png" alt="UCSD">
          <img src="images/goog.png" alt="Google">
          <img src="images/msr.png" alt="Microsoft">
          <img src="images/IIT_Kharagpur_Logo.svg.png" alt="IIT KGP">
        </div>
      </div>
    </section>

    <section class="card-highlight">
      <h3>üî¨ What I'm Working On</h3>
      <ul>
        <li>üß† Building multimodal LLM agents at <a href="https://www.myolab.ai" target="_blank">MyoLab</a>.</li>
        <li>üöÄ Launched a <a href="https://demo.myolab.ai/demo">live demo</a> with motion-text retrieval.</li>
        <li>üì¢ Shared publicly on <a
            href="https://www.linkedin.com/posts/myolab-ai_myo-activity-7346148284551323649-3v68">LinkedIn</a>.
        </li>
        <li>üìù Co-authored <a href="https://arxiv.org/abs/2503.07018" target="_blank">ImplexConv</a>, a new dataset
          and framework for implicit reasoning in personalized multi-session dialogue. <em>(Preprint
            available)</em></li>
      </ul>
    </section>

    <section id="research">
      <h2>Research</h2>
      <p>
        My research focuses on <strong>Large Language Model (LLM)
          reasoning</strong>, <strong>program synthesis</strong>, and
        <strong>multimodal understanding</strong>. I‚Äôm particularly
        interested in enabling LLMs to perform structured, step-by-step
        reasoning in complex environments where inputs span across natural
        language, formal representations (e.g., code, logic), and physical
        modalities such as motion or visual context. This includes
        developing models that can solve problems by abstracting patterns,
        composing subroutines, and leveraging prior examples ‚Äî rather than
        relying on brute-force memorization. I aim to design systems that
        are not only general-purpose and data-efficient, but also
        interpretable and aligned with human-like reasoning capabilities.
      </p>
      <p>
        At <a href="https://www.myolab.ai" target="_blank">MyoLab</a>, I
        work on developing LLM-based agents that interact with embodied
        data (e.g., body movements, sensor inputs) to solve complex
        reasoning tasks. My broader goal is to create learning frameworks
        that combine LLMs with <strong>reinforcement learning</strong> and
        <strong>vision</strong> to enable grounded, goal-directed
        intelligence.
      </p>
      <p>
        üìù I recently co-authored <a href="https://arxiv.org/abs/2503.07018" target="_blank">ImplexConv</a>, a
        large-scale dataset and
        retrieval framework for implicit reasoning in personalized
        multi-session conversations. Our proposed method,
        <strong>TaciTree</strong>, introduces hierarchical multi-level
        summarization to support efficient long-context reasoning.
        <em>(Preprint on <a href="https://arxiv.org/abs/2503.07018">arXiv</a>)</em>
      </p>
    </section>

    <section id="publications">
      <h2>Publications</h2>
      <ul class="publications-list">
        <li>
          <strong>Toward Multi-Session Personalized Conversation:
            ImplexConv</strong><br>
          Xintong Li, <strong>Jalend Bantupalli</strong>, Ria Dharmani,
          Yuwei Zhang, Jingbo Shang<br>
          <em>arXiv Preprint</em>, 2025<br>
          <a href="https://arxiv.org/abs/2503.07018">arXiv</a><br>
          <em>Introduced 2500-example long-term dialogue dataset and
            TaciTree framework for hierarchical summarization.</em>
        </li>
        <li>
          <strong>Flow of Reasoning: Training LLMs for Divergent Problem
            Solving with Minimal Examples</strong><br>
          Contribution: Dataset, Training, Evaluation<br>
          <em>arXiv Preprint</em>, 2024<br>
          <a href="https://arxiv.org/pdf/2406.05673">PDF</a> /
          <a href="https://yu-fangxu.github.io/FoR.github.io/">Project
            page</a><br>
          <em>Achieved SOTA 50.37% on 1D ARC; proposed curriculum-based
            training for LLM generalization.</em>
        </li>
        <li>
          <strong>Decoding Demographic Unfairness from Indian
            Names</strong><br>
          Vahini Medidoddi, <strong>Jalend Bantupalli</strong>, Souvic
          Chakraborty, Animesh Mukherjee<br>
          <em>SocInfo</em>, 2022<br>
          <a href="https://arxiv.org/abs/2209.03089">arXiv</a> /
          <a href="https://github.com/vahini01/IndianDemographics">Code</a><br>
          <em>Created large-scale Indian name datasets; trained
            transformers for gender and caste inference.</em>
        </li>
      </ul>
    </section>

    <section id="media">
      <h2>Media & Mentions</h2>
      <ul>
        <li>
          <strong>Motion-Text Demo shared publicly</strong> on <a
            href="https://www.linkedin.com/posts/myolab-ai_myo-activity-7346148284551323649-3v68"
            target="_blank">LinkedIn</a>.
          Engaged the AI/ML community with discussions around LLMs for
          embodied agents.
        </li>
      </ul>
    </section>
  </main>
</body>

</html>
